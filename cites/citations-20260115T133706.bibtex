@article{10.1098/rsta.2015.0202,
    author = {Jolliffe, Ian T. and Cadima, Jorge},
    title = {Principal component analysis: a review and recent developments},
    journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
    volume = {374},
    number = {2065},
    pages = {20150202},
    year = {2016},
    month = {04},
    abstract = {Large datasets are increasingly common and are often difficult to interpret. Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance. Finding such new variables, the principal components, reduces to solving an eigenvalue/eigenvector problem, and the new variables are defined by the dataset at hand, not a priori, hence making PCA an adaptive data analysis technique. It is adaptive in another sense too, since variants of the technique have been developed that are tailored to various different data types and structures. This article will begin by introducing the basic ideas of PCA, discussing what it can and cannot do. It will then describe some variants of PCA and their application.},
    issn = {1364-503X},
    doi = {10.1098/rsta.2015.0202},
    url = {https://doi.org/10.1098/rsta.2015.0202},
    eprint = {https://royalsocietypublishing.org/rsta/article-pdf/doi/10.1098/rsta.2015.0202/1381479/rsta.2015.0202.pdf},
}



